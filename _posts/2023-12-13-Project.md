# Individual Optional Project

This document will try to explain the coding behind the provided jupyter notebook which participated in the Blue Book for Bulldozers Kaggle Project 

 {:toc}

## About the project

This Kaggle project is about to predict the sale price of a particular piece of heavy equiment at auction based on it's usage, equipment type, and configuaration.  The data is sourced from auction result postings and includes information on usage and equipment configurations.

The fictional enterprise name is ´Fast Iron´ and the data provided has been normalized and the goal of the enterprise is to create a "blue book for bull dozers," for customers to value what their heavy equipment fleet is worth at auction.

Something that is mentioned in the competition is to evaluate the RMSLE((root mean squared log error) between the actual and predicted auction prices.

[link to Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers)

## Description of the dataset

The dataset contains the following fields:

'SalesID', 'SalePrice', 'MachineID', 'ModelID', 'datasource',
 'auctioneerID', 'YearMade', 'MachineHoursCurrentMeter', 'UsageBand',
 'saledate', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc',
 'fiModelSeries', 'fiModelDescriptor', 'ProductSize',
 'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc',
 'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control',
 'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension',
 'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics',
 'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size',
 'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow',
 'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb',
 'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type',
 'Travel_Controls', 'Differential_Type', 'Steering_Controls'

 From which some important variables are:
 
 **| Field | Description |**
 | SalePrice | Contains the values of the price in the auction of the tractor |
 | SalesID | unique identifier of the sale |
 | MachineID |unique identifier of a machine |
 | saledate | date of the sale |
 | Yearmade | Year when the machine was created |
 |UsageBand|Classification of the usage of the machine (Low,medium, high)|

 Also, some additional detail to put is the author of the coding create some functions to create some data arrangement on the dataset. 
 Specially on one column that have some timestamp value, and the coder decided to devide this column in various columns.


 ```python
# Prints '2'
def add_datepart(df, fldnames, drop=True, time=False, errors="raise"):
if isinstance(fldnames,str):
        fldnames = [fldnames]
    for fldname in fldnames:
        fld = df[fldname] # fld = df['saledate']
        fld_dtype = fld.dtype
        if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):
            fld_dtype = np.datetime64

        if not np.issubdtype(fld_dtype, np.datetime64):
            df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)
        targ_pre = re.sub('[Dd]ate$', '', fldname)
        attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',
                'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']
        if time: attr = attr + ['Hour', 'Minute', 'Second']
        for n in attr: 
            if n == 'Week':
                df[targ_pre + n] = getattr(fld.dt.isocalendar(),'week')
            else:
                df[targ_pre + n] = getattr(fld.dt, n.lower())
        df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9
        if drop: df.drop(fldname, axis=1, inplace=True)

```



## Exploring the data 

 One thing to point out on the document is that the author of the coding don't have a section to provide of visual 
 explorations and some statistical exploration on the data. 
 In here it is going to be created an univariate and bivariate analysis to check on the data 
## Data Cleaning
## Featuring Engineering
## Modeling 
## Regression Model
## Decision Tree Model
## Ensambling Methods
## Aditional aspects: about classification modeling


